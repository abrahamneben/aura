Backend CUDA
============

I don't like the name 'backend' any more, it should be called something else:

* platform
* api
* framework
* system
* primitives
* foundation
* service
* service provider



1) device is created from id (or whatever)
2) context is created from device (context is associated with calling thread 
right away)
3) after that, cuda commands can be launched 
4) streams seem to specific to contexts (check this), so a stream should be 
created from a device/context

streams and events are per device

Devices, Streams, and Events
* CUDA streams and events are per device 
    Determined by the GPU thatâ€™s current at the time of their creation
    Each device has its own default stream (aka 0- or NULL-stream)
* Using streams and events 
    Calls to a stream can be issued only when its device is current
    Event can be recorded only to a stream of the same device

For peer 2 peer communication, which context needs to be specified (source or
destination)?

Popping the context every time can be a bad idea when doing low level
programming. A tool should be provided to make a feed permanent.

For CUDA to release memory, the correct context must be set first.


Backend OpenCL
==============

0) opencl has platforms (since there can exist Intel, AMD and Nvidia cards in 
the same system
1) device is created from id (or whatever) and platform
2) a context is created from a device
3) a queue is created from context and device
4) after that, opencl commands can be launched in the queue

devices can share a context
devices can not share a command queue
this slidedeck [0] shows some advantages of 1 context per device over multiple 
devices in context so maybe we should do that 
[0] https://www.cvg.ethz.ch/teaching/2011spring/gpgpu/GPU-multi-device.pdf

let's ignore platforms for now, let's offer all available devices
devices are created and contain a context each and a default command 
queue (a stream)
streams are additional command queues
devices and command queues can be set as defaults per thread

command queues are per device

Rationale
=========

The backend uses typed to initialize, hold and release resources. Types can
have methods but methods must not be used, free functions should always
duplicate functionality of methods to provide a more functional interface.


Interface Duplication
=====================

Interfaces for all backends must currently be duplicated. Also, for the main
interface in the aura namespace, it must also be duplicated in some way. This
is quite tedious. Is there a better way to do this?  A way that is less 
tedious: there could be a single code-base, littered with ifdefs. Not nice,
not less tedious.


